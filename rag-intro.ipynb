{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "63b0fd25-41a2-48ad-b9bf-3f1265308bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.auto import tqdm\n",
    "import requests\n",
    "import tiktoken\n",
    "from decouple import AutoConfig, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7e188bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig(search_path='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "691b0258",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(api_key=config('API-KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5bdaf6ce-2540-494f-989c-5b94b1b6626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "57de60e5-b96c-499c-a7cf-0f30fc33b324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Problem description\\nInfrastructure created in AWS with CD-Deploy Action needs to be destroyed\\nSolution description\\nFrom local:\\nterraform init -backend-config=\"key=mlops-zoomcamp-prod.tfstate\" --reconfigure\\nterraform destroy --var-file vars/prod.tfvars\\nAdded by Erick Calderin',\n",
       " 'section': 'Module 6: Best practices',\n",
       " 'question': 'How to destroy infrastructure created via GitHub Actions',\n",
       " 'course': 'mlops-zoomcamp'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8cc5784e-6515-42e5-be62-8fb915df1088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results, section):\n",
    "    prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "    QUESTION: {question}\n",
    "\n",
    "    CONTEXT:\n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        if section is True:\n",
    "            context = context + f\"S: {doc['section']}\\nQ: {doc['question']}\\nA: {doc['text']}\\n\\n\"\n",
    "        else:\n",
    "            context = context + f\"Q: {doc['question']}\\nA: {doc['text']}\\n\\n\"    \n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "97d35dec-c25f-472d-b961-20d5c30902ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    )\n",
    "\n",
    "    return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a78df1cc-5a5a-40b4-b673-19c7f0319453",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7249d213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\" : \"fe8187192728\",\n",
      "  \"cluster_name\" : \"docker-cluster\",\n",
      "  \"cluster_uuid\" : \"dFPPnYgQQoSKEvHE-sLhQA\",\n",
      "  \"version\" : {\n",
      "    \"number\" : \"8.4.3\",\n",
      "    \"build_flavor\" : \"default\",\n",
      "    \"build_type\" : \"docker\",\n",
      "    \"build_hash\" : \"42f05b9372a9a4a470db3b52817899b99a76ee73\",\n",
      "    \"build_date\" : \"2022-10-04T07:17:24.662462378Z\",\n",
      "    \"build_snapshot\" : false,\n",
      "    \"lucene_version\" : \"9.3.0\",\n",
      "    \"minimum_wire_compatibility_version\" : \"7.17.0\",\n",
      "    \"minimum_index_compatibility_version\" : \"7.0.0\"\n",
      "  },\n",
      "  \"tagline\" : \"You Know, for Search\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl localhost:9200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9367c18-41ad-495e-9920-1a0c552f0d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70fe3c97-916d-42c0-bd7b-4f42d9056409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb6928d413140c9944492ba4610e946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7c72e000-910b-4fb5-aa88-2561e7bc39f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query, course, size, rank):\n",
    "    search_query = {\n",
    "        \"size\": size,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\",],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": course\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "\n",
    "    score_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "        score_docs.append(hit['_score'])\n",
    "    \n",
    "    print(f\"source: {result_docs[rank-1]}\")\n",
    "    print(f\"rank: {score_docs[rank-1]}\")\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "81abecbc-eb6b-428f-ab7d-7e21f58b64de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, course = \"data-engineering-zoomcamp\", size = 5, rank = 1, section = False):\n",
    "    search_results = elastic_search(query, course, size, rank)\n",
    "    prompt = build_prompt(query, search_results, section)\n",
    "    print(f'prompt:\\n {prompt[:400]}')\n",
    "    print(f'prompt length: {len(prompt)}')\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0ea9315a-a619-4066-9e90-8c260f2c8450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: {'text': 'Install the astronomer-cosmos package as a dependency. (see Terraform example).\\nMake a new folder, dbt/, inside the dags/ folder of your Composer GCP bucket and copy paste your dbt-core project there. (see example)\\nEnsure your profiles.yml is configured to authenticate with a service account key. (see BigQuery example)\\nCreate a new DAG using the DbtTaskGroup class and a ProfileConfig specifying a profiles_yml_filepath that points to the location of your JSON key file. (see example)\\nYour dbt lineage graph should now appear as tasks inside a task group like this:', 'section': 'Course Management Form for Homeworks', 'question': 'How to run a dbt-core project as an Airflow Task Group on Google Cloud Composer using a service account JSON key', 'course': 'data-engineering-zoomcamp'}\n",
      "rank: 31.973522\n",
      "prompt:\n",
      " You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
      "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "\n",
      "    QUESTION: How do execute a command on a Kubernetes pod?\n",
      "\n",
      "    CONTEXT:\n",
      "    S: Course Management Form for Homeworks\n",
      "Q: How to run a dbt-core project as an Airflow Task Group on Google Cloud Composer using a service account JSON \n",
      "prompt length: 3824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There is no information in the provided context on how to execute a command on a Kubernetes pod. The context only discusses topics related to Data Engineering, MLOps, Machine Learning, PySpark, and analytics engineering with dbt, but does not mention Kubernetes.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'How do execute a command on a Kubernetes pod?'\n",
    "\n",
    "rag(query, section = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ec118c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: {'text': 'You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan', 'section': '5. Deploying Machine Learning Models', 'question': 'How do I copy files from a different folder into docker container’s working directory?', 'course': 'machine-learning-zoomcamp'}\n",
      "rank: 59.812744\n",
      "prompt:\n",
      " You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
      "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "\n",
      "    QUESTION: How do copy a file to a Docker container?\n",
      "\n",
      "    CONTEXT:\n",
      "    Q: How do I debug a docker container?\n",
      "A: Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\n",
      "doc\n",
      "prompt length: 1462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To copy a file to a Docker container, you can use the `docker cp` command. The basic syntax is as follows: \\n`docker cp /path/to/local/file_or_directory container_id:/path/in/container` \\n\\nReplace `/path/to/local/file_or_directory` with the path to the file you want to copy, `container_id` with the ID of the Docker container, and `/path/in/container` with the path where you want to copy the file in the container.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How do copy a file to a Docker container?\"\n",
    "\n",
    "rag(query, \"machine-learning-zoomcamp\", 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "953e43bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: {'text': 'You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan', 'section': '5. Deploying Machine Learning Models', 'question': 'How do I copy files from a different folder into docker container’s working directory?', 'course': 'machine-learning-zoomcamp'}\n",
      "rank: 59.812744\n",
      "[63842, 261, 4165, 14029, 29186, 13, 30985, 290, 150339, 4122, 402, 290, 31810, 8099, 591, 290, 40251, 7862, 558, 271, 7649, 1606, 290, 19719, 591, 290, 31810, 8099, 1261, 55959]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "\n",
    "query = \"How do copy a file to a Docker container?\"\n",
    "\n",
    "search_results = elastic_search(query, \"machine-learning-zoomcamp\", 3, 3)\n",
    "\n",
    "prompt = build_prompt(query, search_results, False)\n",
    "\n",
    "tokens = encoding.encode(prompt)\n",
    "\n",
    "print(tokens[:30])\n",
    "\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "078eefa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You\\'re a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\\n    Use only the facts from the CONTEXT when answering the QUESTION.\\n\\n    QUESTION: How do copy a file to a Docker container?\\n\\n    CONTEXT:\\n    Q: How do I debug a docker container?\\nA: Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)\\n\\nQ: How do I copy files from my local machine to docker container?\\nA: You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\\n\\nQ: How do I copy files from a different folder into docker container’s working directory?\\nA: You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "23bc893a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To copy a file to a Docker container, you can use the `docker cp` command. The basic syntax is as follows: \\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container \\n\\nYou need to replace `/path/to/local/file_or_directory` with the path to the file you want to copy, `container_id` with the ID of the running Docker container, and `/path/in/container` with the path where you want to copy the file in the container.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = llm(prompt)\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f613f817",
   "metadata": {},
   "source": [
    "Llama-3.3-70B-Versatile is Meta's advanced multilingual large language model, optimized for a wide range of natural language processing tasks. With 70 billion parameters, it offers high performance across various benchmarks while maintaining efficiency suitable for diverse applications.\n",
    "\n",
    "Input Token Price\t$0.59 per 1M tokens\n",
    "\n",
    "Output Token Price\t$0.79 per 1M tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a9acc366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pricing\n",
    "INPUT_COST_PER_TOKEN = 0.59 / 1000000  # $ per token\n",
    "OUTPUT_COST_PER_TOKEN = 0.79 / 1000000\n",
    "\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def calculate_cost(input_text: str, output_text: str) -> dict:\n",
    "    input_tokens = count_tokens(input_text)\n",
    "    output_tokens = count_tokens(output_text)\n",
    "\n",
    "    input_cost = input_tokens * INPUT_COST_PER_TOKEN\n",
    "    output_cost = output_tokens * OUTPUT_COST_PER_TOKEN\n",
    "    total_cost = input_cost + output_cost\n",
    "\n",
    "    return {\n",
    "        \"input_tokens\": input_tokens,\n",
    "        \"output_tokens\": output_tokens,\n",
    "        \"input_cost\": f\"${round(input_cost, 6)}\",\n",
    "        \"output_cost\": f\"${round(output_cost, 15)}\",\n",
    "        \"total_cost\": f\"${round(total_cost, 6)}\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9e9e435c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 324,\n",
       " 'output_tokens': 99,\n",
       " 'input_cost': '$0.000191',\n",
       " 'output_cost': '$7.821e-05',\n",
       " 'total_cost': '$0.000269'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = prompt\n",
    "\n",
    "output_text = answer\n",
    "\n",
    "cost_info = calculate_cost(input_text, output_text)\n",
    "\n",
    "cost_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
